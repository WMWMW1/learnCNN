{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个关于pytorch的，不严谨教学，没有关于线性代数和反向传播的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install torchvision\n",
    "%pip install torch\n",
    "%pip install matplotlib\n",
    "#先安装好依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the input size and output size of the linear layer\n",
    "input_size = 10\n",
    "output_size = 5\n",
    "linear_layer = nn.Linear(input_size, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他只能传入TORCH.TENSOR的对象，所以在与其他对象交互的时候，比如游戏场景就需要把所需的信息转成TORCH.TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Python数组\n",
    "python_array = [1, 2, 3, 4, 5]\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "torch_tensor = torch.tensor(python_array)\n",
    "\n",
    "print(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 二维Python数组\n",
    "python_2d_array = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "torch_2d_tensor = torch.tensor(python_2d_array)\n",
    "\n",
    "print(torch_2d_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch可以创建随机 tensor，可以用来测试或者初始化神经网络，生成噪声(总之有用)数据增强、模拟实验、概率模型。。。。。下面是示例一个维度为（1， 刚刚定义的inputsize）的随机 tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, input_size)\n",
    "print(input)\n",
    "print(input.shape)#shape 可以看到矩阵的维度，这个矩阵是1行10列的\n",
    "#第一个维度在pytorch中是batch size，一般在训练的时候是多个样本一起训练，所以第一个维度是batch size\n",
    "#我们不需要管理第一个维度，pytorch会自动管理这个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output = linear_layer(input)\n",
    "print(output.size())\n",
    "print(output)\n",
    "#input是1行10列的矩阵，linear_layer是10行5列的矩阵\n",
    "#output的size是1行5列，这个矩阵是由input矩阵通过linear_layer得到的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个linear xw+b的过程就是神经网络的前向传播过程\n",
    "#w的维度是10行5列，b的维度是1行5列\n",
    "#现在我们提取w和b\n",
    "w = linear_layer.weight\n",
    "b = linear_layer.bias\n",
    "print('shape of w:', w.size())\n",
    "print('shape of b:', b.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在是pytorch写一个神经网络的基本方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear_1 = nn.Linear(10, 5)\n",
    "        self.linear_2 = nn.Linear(5, 2)\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "mlp = MLP()\n",
    "input = torch.randn(1, 10)\n",
    "output = mlp(input)\n",
    "print(output.size())\n",
    "#这里相当于定义了一个两层的神经网络，输入是10维，第一层是10维到5维，第二层是5维到2维\n",
    "#这个神经网络的前向传播过程是先通过第一层，再通过第二层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward向前计算就是推理，用户可以自己定义这个步骤，通过这种办法来达到很多操作比如 决定神经网络的计算顺序\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#现在我们来看看这个神经网络的参数直接打印出来是什么样的\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "# 这是一个nmist数据集\n",
    "#\n",
    "#trainset是训练集，testset是测试集\n",
    "print(len(trainset))\n",
    "print(len(testset))\n",
    "#trainset和testset都是一个数据集，里面有60000个样本,被分成了两个数据集，一个是训练集，一个是测试集，确保训练集和测试集是独立的\n",
    "# print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainset[0])\n",
    "#trainset[0]是一个tuple，第一个元素是一个图片，第二个元素是一个标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('0', '1', '2', '3',\n",
    "              '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "#这里我们展示了4张图片，每张图片对应一个标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在开始尝试训练 \n",
    "我们需要重构模型\n",
    "因为这个数据集是28x28\n",
    "的灰度图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义神经网络模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear_1 = nn.Linear(784, 128)  # 输入层为784，因为mnist数据集的图片大小是28*28=784\n",
    "        self.relu = nn.ReLU()                # 增加非线性激活函数\n",
    "        self.linear_2 = nn.Linear(128, 10)   # 输出层为10t因为mnist数据集有10个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # 将输入的二维图像张量展平为一维\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "mlp = MLP()\n",
    "\n",
    "# 将模型移动到GPU上\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mlp.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, loss_function):\n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "    \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return average_loss, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是在测试集里测试准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, loss_function):\n",
    "    model.eval() # 将模型设置为评估模式\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            test_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写一个循环来做训练和测试\n",
    "# train(mlp, trainloader, criterion, optimizer)\n",
    "# test(mlp, testloader, criterion）\n",
    "\n",
    "#现在我们把训练和测试的代码封装到一个函数里面\n",
    "\n",
    "def train_test_loop(model, train_loader, test_loader, optimizer, loss_function, num_epochs, device, save_path='model_checkpoint/', scheduler=None, checkpoint_filename=None, save_frequency=1):\n",
    "    start_epoch = 0\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, loss_function)\n",
    "        test_loss, test_accuracy = test(model, device, test_loader, loss_function)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP().to(device)\n",
    "num_epochs=4\n",
    "# train_test_loop(model,train_loader, test_loader, \n",
    "#                 optimizer, \n",
    "#                 loss_function, \n",
    "#                 num_epochs,device,\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两层linear一般效果不会很好\n",
    "换成cnn试试\n",
    "\n",
    "\n",
    "cnn在图像数据上效果会更好\n",
    "在pytorch中，cnn的每层的组件是torch.nn.Conv2d\n",
    "这个组件的每一个参数是（输入的通道数，输出的通道数，卷积核的大小，卷积核的步长）\n",
    "比如torch.nn.Conv2d(3, 16, 3, 1)表示输入的通道数是3，输出的通道数是16，卷积核的大小是3*3，卷积核的步长是1\n",
    "卷积核可以被看作是一个滤波器，它会在输入的图像上滑动，每次滑动的距离是步长，然后计算卷积核和图像的内积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#下面是卷积的示例 \n",
    "conv = nn.Conv2d(3, 16, 3, 1)\n",
    "input = torch.randn(1, 3, 32, 32)#输入的通道数是3，输入的图像大小是32*32,第一个维度是batch size不用管\n",
    "output = conv(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是为什么输出的高宽不是一致的？\n",
    "\n",
    "根据这些参数，可以计算输出张量的大小。输出张量的尺寸由以下公式确定：\n",
    "\n",
    "$$\n",
    "\\text{output\\_size} = \\left\\lfloor \\frac{\\text{input\\_size} - \\text{kernel\\_size} + 2 \\times \\text{padding}}{\\text{stride}} + 1 \\right\\rfloor\n",
    "$$\n",
    "\n",
    "其中，$\\text{input\\_size}$ 是输入张量的大小，$\\text{kernel\\_size}$ 是卷积核大小，$\\text{padding}$ 是填充大小，$\\text{stride}$ 是步长。\n",
    "\n",
    "根据给定的参数：\n",
    "\n",
    "- $\\text{input\\_size} = 32$ （输入图像大小）\n",
    "- $\\text{kernel\\_size} = 3$ （卷积核大小）\n",
    "- $\\text{padding} = 0$ （默认情况下没有填充）\n",
    "- $\\text{stride} = 1$ （步长）\n",
    "\n",
    "代入公式得到：\n",
    "\n",
    "$$\n",
    "\\text{output\\_size} = \\left\\lfloor \\frac{32 - 3 + 2 \\times 0}{1} + 1 \\right\\rfloor = \\left\\lfloor \\frac{29}{1} + 1 \\right\\rfloor = 30\n",
    "$$\n",
    "\n",
    "因此，输出张量的大小为 `torch.Size([1, 16, 30, 30])`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#现在加上填充这样输出的图像大小和输入的图像大小是一样的\n",
    "conv = nn.Conv2d(3, 16, 3, 1, padding=1)\n",
    "input = torch.randn(1, 3, 32, 32)\n",
    "output = conv(input)\n",
    "print(output.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个3x3的图像，我们假设一个2x2的卷积核，步长是1，那么输出的图像大小是2x2。\n",
    "\n",
    "输入图像：\n",
    "\n",
    "|   |   |   |\n",
    "|---|---|---|\n",
    "| 1 | 2 | 3 |\n",
    "| 4 | 5 | 6 |\n",
    "| 7 | 8 | 9 |\n",
    "\n",
    "卷积核：\n",
    "\n",
    "|   |   |\n",
    "|---|---|\n",
    "| 1 | 2 |\n",
    "| 3 | 4 |\n",
    "\n",
    "输出图像（计算过程）：\n",
    "\n",
    "|   |   |\n",
    "|---|---|\n",
    "| 1*1+2*2+4*3+5*4=44 | 2*1+3*2+5*3+6*4=56 |\n",
    "| 4*1+5*2+7*3+8*4=68 | 5*1+6*2+8*3+9*4=80 |\n",
    "\n",
    "输出图像：\n",
    "\n",
    "|    |    |\n",
    "|----|----|\n",
    "| 44 | 56 |\n",
    "| 68 | 80 |\n",
    "\n",
    "我们可以看到输出的图像是2x2的。\n",
    "\n",
    "如果我们加上padding=1，那么输入图像变成了：\n",
    "\n",
    "|   |   |   |   |   |\n",
    "|---|---|---|---|---|\n",
    "| 0 | 0 | 0 | 0 | 0 |\n",
    "| 0 | 1 | 2 | 3 | 0 |\n",
    "| 0 | 4 | 5 | 6 | 0 |\n",
    "| 0 | 7 | 8 | 9 | 0 |\n",
    "| 0 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "卷积核仍然是：\n",
    "\n",
    "|   |   |\n",
    "|---|---|\n",
    "| 1 | 2 |\n",
    "| 3 | 4 |\n",
    "\n",
    "输出图像\n",
    "\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 4 | 11 | 18 | 11 |\n",
    "| 18 | 44 | 56 | 37 |\n",
    "| 32 | 68 | 80 | 53 |\n",
    "| 18 | 44 | 56 | 37 |\n",
    "\n",
    "\n",
    "我们可以看到，加上padding后，输出的图像变成了4x4。\n",
    "\n",
    "\n",
    "\n",
    "实际上卷积层的卷积核的数字是可以通过训练来学习的\n",
    "他其实可以被看作一个线性层，我们下面演示一下他们的等价性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 定义卷积层\n",
    "in_channels = 1\n",
    "out_channels = 3\n",
    "kernel_size = 2\n",
    "\n",
    "#我们用相同的权重和偏置来定义一个卷积层和一个等效的线性层\n",
    "# 定义卷积层\n",
    "conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=0)\n",
    "same_weights = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "same_bias = torch.randn(out_channels)\n",
    "\n",
    "conv_layer.weight = nn.Parameter(same_weights)\n",
    "conv_layer.bias = nn.Parameter(same_bias)\n",
    "\n",
    "# 定义等效的线性层\n",
    "# 展开卷积核为线性层的权重\n",
    "linear_layer = nn.Linear(in_features=in_channels*kernel_size*kernel_size, out_features=out_channels, bias=True)\n",
    "#我们用相同的权重和偏置来定义一个卷积层和一个等效的线性层\n",
    "linear_layer.weight = nn.Parameter(same_weights.view(out_channels, -1))#view是reshape的意思,-1表示自动计算,这里是把卷积核展平\n",
    "\n",
    "\n",
    "linear_layer.bias = nn.Parameter(same_bias)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\"\"原始权重的维度是{same_weights.shape}\\n\"\"\",\n",
    "      same_weights)\n",
    "\n",
    "print(f\"\"\"扁平化:我们减少了一个维度\\n\n",
    "      现在是一个二维的张量{same_weights.view(out_channels, -1).shape}\\n\n",
    "      \"\"\",same_weights.view(out_channels, -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一个假设的输入图像\n",
    "image = torch.randn(1, in_channels, 3, 3)  # (N, C, H, W)\n",
    "print(\"Image:\\n\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积操作\n",
    "torch_conv_result = conv_layer(image)\n",
    "print(\"Convolution Result:\\n\", torch_conv_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动卷积\n",
    "H, W = image.shape[2], image.shape[3]\n",
    "output_height = H - kernel_size + 1\n",
    "output_width = W - kernel_size + 1\n",
    "\n",
    "# 初始化输出张量\n",
    "conv_result_manual = torch.zeros((1, out_channels, output_height, output_width))\n",
    "\n",
    "# 循环遍历每个卷积区域\n",
    "for i in range(output_height):\n",
    "    for j in range(output_width):\n",
    "        region = image[:, :, i:i+kernel_size, j:j+kernel_size]  # 提取当前2x2区域\n",
    "        region = region.reshape(1, -1)  # 使用.reshape()代替.view()\n",
    "        for k in range(out_channels):\n",
    "            # 计算卷积：点积加偏置\n",
    "            conv_result_manual[:, k, i, j] = (linear_layer.weight[k] * region).sum() + linear_layer.bias[k]\n",
    "\n",
    "\n",
    "\n",
    "#这里的 i是图片的x轴，j是图片的y轴\n",
    "#每次取一个2*2的区域，然后把这个区域展平，然后和权重做点积，再加上偏置，就是卷积的结果\n",
    "#这个过程是手动实现的，和pytorch的conv2d是一样的\n",
    "#region是一个2*2的区域，展平之后是一个1*4的向量\n",
    "#\n",
    "\n",
    "print(\"Manual Convolution Result:\\n\", conv_result_manual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们可以拿nmist的第一个图片试一下\n",
    "image = trainset[0][0].unsqueeze(0)\n",
    "print(image.size())\n",
    "torch_conv_result = conv_layer(image)\n",
    "print(torch_conv_result.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "def my_conv2d(image, kernel, bias, kernel_size, out_channels):\n",
    "    # image dimensions and kernel dimensions are assumed to be correctly provided\n",
    "    _, _, H, W = image.shape  # Image dimensions (N, C, H, W)\n",
    "    output_height = H - kernel_size + 1\n",
    "    output_width = W - kernel_size + 1\n",
    "\n",
    "    # Initialize the output tensor\n",
    "    conv_result_manual = torch.zeros((1, out_channels, output_height, output_width))\n",
    "\n",
    "    # Loop over every pixel in the output feature map\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            # Extract the current region to apply the kernel on\n",
    "            region = image[:, :, i:i+kernel_size, j:j+kernel_size]\n",
    "            region = region.reshape(1, -1)  # Flatten the region\n",
    "\n",
    "            # Compute the convolution for each output channel\n",
    "            for k in range(out_channels):\n",
    "                # Perform element-wise multiplication followed by sum, then add bias\n",
    "                conv_result_manual[:, k, i, j] = (kernel[k].reshape(1, -1) * region).sum() + bias[k]\n",
    "\n",
    "    return conv_result_manual\n",
    "\n",
    "# Parameters\n",
    "in_channels = 1\n",
    "out_channels = 3\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "padding = 0\n",
    "\n",
    "# Define the weights for the convolution kernel and the biases\n",
    "same_weights = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "same_bias = torch.randn(out_channels)\n",
    "\n",
    "image = trainset[0][0].unsqueeze(0)\n",
    "# Perform convolution\n",
    "manual_convolution_result = my_conv2d(image, same_weights, same_bias, kernel_size, out_channels)\n",
    "\n",
    "# Plotting the original image and the feature maps\n",
    "fig, axs = plt.subplots(1, out_channels + 1, figsize=(15, 5))  # +1 for the original image\n",
    "\n",
    "# Plot original image\n",
    "axs[0].imshow(image[0, 0, :, :], cmap='gray')\n",
    "axs[0].title.set_text('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Plot each feature map\n",
    "for i in range(out_channels):\n",
    "    axs[i+1].imshow(manual_convolution_result[0, i, :, :], cmap='gray')\n",
    "    axs[i+1].title.set_text(f'Feature Map {i+1}')\n",
    "    axs[i+1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "in_channels = 1\n",
    "out_channels = 3\n",
    "kernel_size = 2\n",
    "\n",
    "# Convolution layer setup\n",
    "conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=0)\n",
    "\n",
    "\n",
    "conv_layer.weight = nn.Parameter(same_weights)\n",
    "conv_layer.bias = nn.Parameter(same_bias)\n",
    "\n",
    "# Convolution operation\n",
    "torch_conv_result = conv_layer(image)\n",
    "\n",
    "# Detach the result for visualization\n",
    "torch_conv_result = torch_conv_result.detach()\n",
    "\n",
    "# Setting up the plot\n",
    "fig, axs = plt.subplots(1, out_channels + 1, figsize=(15, 5))  # +1 for the original image\n",
    "\n",
    "# Plot original image\n",
    "axs[0].imshow(image[0, 0, :, :].numpy(), cmap='gray')  # Convert tensor to numpy array\n",
    "axs[0].title.set_text('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Plot each feature map\n",
    "for i in range(out_channels):\n",
    "    axs[i+1].imshow(torch_conv_result[0, i, :, :].numpy(), cmap='gray')  # Detach and convert tensor\n",
    "    axs[i+1].title.set_text(f'Feature Map {i+1}')\n",
    "    axs[i+1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到他们得到的效果都是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)  # input channels = 1, output channels = 32, kernel size = 3, stride = 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)  # input channels = 32, output channels = 64, kernel size = 3, stride = 1\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(12*12*64, 128)  # considering the output dimension of the last conv layer with pooling\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST digits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # should refer to 'model.parameters()' not 'mlp.parameters()'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs=4\n",
    "train_test_loop(model,train_loader, test_loader, \n",
    "                optimizer, \n",
    "                loss_function, \n",
    "                num_epochs,device,\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = my_conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.conv2 = my_conv2d(32, 64, kernel_size=3, stride=1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(12*12*64, 128)  # assuming input images are 28x28 and pooled once\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST digits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class my_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(my_conv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.weights = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, height, width = x.shape\n",
    "        height_out = int((height - self.kernel_size) / self.stride + 1)\n",
    "        width_out = int((width - self.kernel_size) / self.stride + 1)\n",
    "\n",
    "        output = torch.zeros((batch_size, self.out_channels, height_out, width_out)).to(x.device)\n",
    "\n",
    "        for i in range(height_out):\n",
    "            for j in range(width_out):\n",
    "                h_start = i * self.stride\n",
    "                h_end = h_start + self.kernel_size\n",
    "                w_start = j * self.stride\n",
    "                w_end = w_start + self.kernel_size\n",
    "\n",
    "                region = x[:, :, h_start:h_end, w_start:w_end]\n",
    "                for k in range(self.out_channels):\n",
    "                    output[:, k, i, j] = torch.sum(region * self.weights[k].unsqueeze(0), dim=[1, 2, 3]) + self.bias[k]\n",
    "\n",
    "        return output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # should refer to 'model.parameters()' not 'mlp.parameters()'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs=4\n",
    "train_test_loop(model,train_loader, test_loader, \n",
    "                optimizer, \n",
    "                loss_function, \n",
    "                num_epochs,device,\n",
    "                )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
